> **Disclaimer:** Solo estÃ¡n publicados los procesos de entrevista en los que no se aclarÃ³ que no se podÃ­a difundir el material entregado. Las consignas originales no estÃ¡n incluidas. Si alguien desea que su proceso sea dado de baja, puede enviar un mail a marianojosecrosetti@gmail.com.

# EdenMed Segmentation Challenge

![Python](https://img.shields.io/badge/python-3.10-blue.svg)
![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)

# Uso rÃ¡pido

#### InstalaciÃ³n

Instalar las dependencias con:
```
pip install -r requirements.txt
```

#### Segmentar una imÃ¡gen

Se puede utilizar el modelo de segmentaciÃ³n en una imÃ¡gen con el comando:
```
python segmentation.py --image data/test_classifier/a.jpg --model models/unet-6v.pt --out mask.jpg
```

> Segmentation finished!
> Mask was generated: mask.jpg

#### Determinar si la imÃ¡gen corresponde a un torax

Para previamente determinar si la imÃ¡gen contiene un torax se puede usar:

```
python torax_detection.py --image data/test_classifier/a.jpg --model models/torax_detector_model.pth
```
Output (clase y probabildiad respectiva):
> class=torax
> confidence=0.84

#### SoluciÃ³n al dataset suministrado

El dataset suministrado (`data/challenge_data`) se dividiÃ³ en imÃ¡genes de tÃ³rax e imÃ¡genes que no correspondÃ­an a tÃ³rax (`data/binary_dataset`) utilizando el clasificador (`torax_detection.py`) y las imÃ¡genes respectiva a tÃ³rax se segmentaron utilizando el modelo de segmentaciÃ³n mencionado (`segmentation.py`) produciÃ©ndo finalmente las mÃ¡scaras que se incluyeron en `data/binary_dataset_torax_masks`.

# Informe

Las siguientes secciones incluyen la guÃ­a paso a paso de cÃ³mo se ha resuelto el challenge.

## Data exploration

En la base de datos suministrada hay 3 tablas:

> Table: study_patient_data
>  Columns: study_id, body_parts, modalities, patient_age, patient_gender
> Rows: 549

Contiene informaciÃ³n sobre el estudio en particular (tipo de modalidad, secciÃ³n estudiada, datos del paciente).

> Table: study_instances
>  Columns: study_id, instance_id, measurement_data, file_name
>  Rows: 460

Para cada estudio, contiene una serie de datos de mediciÃ³n e imÃ¡genes asosciadas.
Nota: para cada `study_id` se encontrÃ³ un Ãºnico `file_name` asosciado.

> Table: study_report
>  Columns: study_id, report_id, report_value
>  Rows: 555
>

Para cada estudio, contiene un reporte en HTML escrito en lenguaje natural espaÃ±ol.

![Tablas presentes en la base de datos](./images/tables.png)

**Otras Observaciones:**
- `study_patient_data` contiene una Ãºnica fila por `study_id`.
- `study_instances` contiene varias instancias por `study_id`, pero una Ãºnica imagen respectiva `file_name`.
- `study_id` contiene varios reportes por `study_id`.
- Existen `sutdy_id` que no tienen imÃ¡genes asosciadas (esto se desprende simplemente de ver la cantidad de filas).
- Existen `file_name` para los cuales no existe una imagen jpeg respectiva.

Todas  estas observaciones pueden corroborarse ejecutando `python db.py` que correrÃ¡ estos chequeos.

### ExploraciÃ³n de caracterÃ­sticas demogrÃ¡ficas de los pacientes

Se ha calculado:
- La composiciÃ³n de los estudios por sexo.
- La composiciÃ³n de los estudios por edad del paciente.
- La composiciÃ³n de los estudios por modalidad (CT, CX, DT, DX).
- La distribuciÃ³n de los CTR.
**Nota**: el cÃ³digo que genera los grÃ¡ficos estÃ¡ en la notebook: `notebook.ipynb`

![ComposiciÃ³n de los estudios por sexo.](./images/sex_composition.png)

![ComposiciÃ³n de los estudios por edad.](./images/age.png)
![ComposiciÃ³n de los estudios por modalidad.](./images/modalities_composition.png)
![DistribuciÃ³n CTR](./images/ctr.png)

### Propuesta para el anÃ¡lisis de los reportes mÃ©dicos

Para el anÃ¡lisis de los reportes mÃ©dicos se propone generar una ontologÃ­a para cada reporte.
La ontologÃ­a es una secuencia de pares (clave, valor) extrayendo todos los datos estructurados del reporte que se encuentren.
Se realiza utilizando un LLM. Actualmente se usa gpt-4o de OpenAI aunque fÃ¡cilmente se podrÃ­a adaptar para usar otra interfaz.
AdemÃ¡s de eso, clasifica en "NORMAL" y "ANORMAL" cada observaciÃ³n.

Por ejemplo el reporte:

````{verbatim}
La arteria pulmonar de 16mm. (normal hasta 17mm).La regiÃ³n parahiliar sin ensanchamientos que sugieran alteraciones. El mediastino superior de aspecto normal. La silueta cardiaca con eje aparentemente normal, de perfiles y contornos conservados con un Ã­ndice cardiotorÃ¡cico de .42 (normal hasta .5) Las estructuras vasculares, vena cava superior, aorta y arterias pulmonares sin alteraciones.
````

GenerarÃ­a la siguiente ontologÃ­a:
```
NORMAL
arteria_pulmonar.mm = 16
region_parahiliar.ensanchamientos = False
rmediastino_superior.normal = True
silueta_cardiaca.normal = True
indice_cardiotorÃ¡cico = 0.42
ANORMAL
estructuras_vasculares.alteraciones = True
vena_cava_superior.alteraciones = True
aorta.alteraciones = True
arterias pulmonares.alteraciones = True
columna_lumbar.cambios_osteodegenerativos = True
columna_lumbar.escoliosis_izquierda = True
```

El prompt para generar dichas ontologÃ­as se encuentra en `ontology.py`

#### Analizando los reportes

La ventaja de este abordaje es que permite realizar anÃ¡lisis de los reportes con simples reglas, recorriendo la ontologÃ­a generada y las llamadas a la API de LLM (lento y costoso) se hace una sÃ³la vez. 

En las siguientes subsecciones se encuentran algunos anÃ¡lisis que se pueden realizar (el cÃ³digo respectivo para calcularlo estÃ¡ en `notebook.ipynb`).

La ontologÃ­a de cada estudio estÃ¡ guardada en `data/ontology.pkl` y el cÃ³digo usado para calcularla estÃ¡ en `ontology.py`

##### Histograma de distribuciÃ³n de Ãngulo de Ferguson

![IHistograma de distribuciÃ³n de Ãngulo de Ferguson](./images/ferguson_angles.png)

##### Casos diagnosticados de escoleosis

```
14 casos con escoliosis: 
- 003b88ed-bdd5-4bac-89b2-c170d9418d75
- 0403dfdd-9ac4-4d6b-86ab-fb3647e90891
- 082ca1b1-a9a2-4c77-9a55-64f06c920f4b
- 0df07efa-1e39-4c57-96cf-eee4a2e16eff
- 1ec28fe0-2868-494b-b129-21caf9a01927
- 21e23158-711c-478a-8429-0ac9caa00484
- 4aa65847-6f5f-4559-8bd0-7482ed01f097
- 5c016336-0d4e-4b7f-aa33-a518f00b0bf4
- 904c8271-12a2-4015-9f62-f5ea97fe2337
- a1e11c71-583e-4620-90eb-ebe901676694
- a225cdb1-ec06-428f-8aa2-f19bf892000a
- b43aeabc-f687-4aa6-976d-489a9ecb8ed2
- daf33fc7-870a-424b-a169-d538f21d2fa2
- f97c2d0e-c063-4b02-adbb-ca67e154f2b5
```

## ConstrucciÃ³n del dataset

#### Unificando las tablas

Tener 3 tablas normalizadas es Ãºtil para el funcionamiento de un sistema transaccional. Pero a la hora de operar con datos de forma analÃ­tica lo mejor es tener toda la informaciÃ³n en **una sÃ³la tabla** (por mÃ¡s que no estÃ© normalizada). Para ello se:
1. AgrupÃ³ por `study_id` las tablas `study_instances` y `study_report`. Las columnas se agregaron como listas de valores.
2. Se hizo un merge (JOIN de tablas) por `study_id`.
3. Se eliminaron filas que no contenÃ­an un `file_name` o para el cuÃ¡l no existÃ­an imÃ¡genes asosciadas.

Esto se encuentra en la funciÃ³n `db.create_dataset`:

#### Seleccionando las imÃ¡genes de tÃ³rax

Ahora debemos seleccionar las imÃ¡genes que correspondan efectivamente a torax. Analizando los `body_parts` vemos los siguientes valores:

> {'TÃ“RAX', 'L SPINE', 'TORAX TORAX LATERAL', 'COLUMNA', 'BREAST', 'DEFAULT', 'LSPINE', 'SHOULDER', 'COLUMNA COLUMNA-L/S LATERAL', 'Pectoral', 'COL. LUMBAR', 'CSPINE', 'TORAX', 'PELVIS', 'TORAX TORAX PA', 'Senos Paranasales', 'NECK', 'THORAX', 'SPINE LUMBAR', 'PNS', 'L-SPINE', 'ABDOMEN', 'CHEST', 'OTHER', 'L/S-SPINE', 'HEAD', 'COLUMNA COLUMNA-L/S AP', 'ANGIO'}

Para seleccionar vamos a realizar los siguientes pasos:
1. Una primera selecciÃ³n naive, basada en `body_parts` razonables, para separarlos en clases `torax` y `not_torax`.
2. Limpiar a manualmente cada una de las dos carpetas. Para eso:
a. Viendo las miniaturas de las imÃ¡genes en `torax` seleccionamos las que no sean de torax y las movemos a la carpeta `not_torax_cleaned`.
b. Viendo las miniaturas de las imÃ¡genes en `not_torax` seleccionamos las que SI sean de torax y las movemos a la carpeta `torax_cleaned`.
c. Finalmente copiamos los archivos restantes en `not_torax` y `torax` a `torax_cleaned` y `not_torax_cleaned`.
**Observacion**: podemos hacer un limpiado a mano rÃ¡pidamente viendo las imÃ¡genes como minuaturas por dos razones. En primer lugar nuestras clases son fÃ¡cilmente identificables (podemos hacerlo viendo la miniatura). En segundo lugar, tenemos pocas imÃ¡genes (alrededor de 300).
Luego de este paso estaremos en condiciones de **entrenar un clasificador binario** lo que nos permitirÃ¡ tener una selecciÃ³n mÃ¡s precisa para imÃ¡genes futuras (para las cuales, ademÃ¡s, podemos no tener datos como `body_part`).
3. Pondremos estas dos clases en la carpeta `binary_dataset` y entranaremos un clasificador binario basado en `Resnet`.

El modelo de selecciÃ³n de tÃ³rax quedÃ³ guardado en `models/torax_detector_model.pth` y puede ser usado en una imagen de la siguiente manera:
```
python torax_detection.py --image data/test_classifier/a.jpg --model models/torax_detector_model.pth
```
Output (clase y probabildiad respectiva):
> class=torax
> confidence=0.84

Ejemplos de imÃ¡genes de internet clasificadas:

![ImÃ¡genes de internet clasificadas por el clasificador entrenado](./images/classifier_results.png)

## Segementando pulmones

Para la segmentaciÃ³n pulmonar se ha utilizado una arquitectura U-Net (ver ApÃ©ndice II: Referencias).
La misma ha sido entrenada con **Montgomery** y **Shenzhen** datasets de readiografÃ­as de torax (ver ApÃ©ndice I: Datasets).
El cÃ³digo que se ha utilizado es el de [Repositorio de segmentaciÃ³n pulmonar (GitHub)](https://github.com/IlliaOvcharenko/lung-segmentation).

Un ejemplo de una imÃ¡gen del dataset superpuesta con la mÃ¡scara generada por el modelo:

![Ejemplo de imÃ¡gen superpuesta por su mÃ¡scara de segmentaciÃ³n.](./images/segmentation_example.png)

Se puede utilizar el modelo de segmentaciÃ³n en una imÃ¡gen con el comando:
```
python segmentation.py --image data/test_classifier/a.jpg --model models/unet-6v.pt --out mask.jpg
```

> Segmentation finished!
> Mask was generated: mask.jpg

El comando anterior generarÃ¡ una imagen blanco y negro con la mÃ¡scara en el path que se le indique en el argumento --out

![ComposiciÃ³n de los estudios por modalidad.](./images/output_mask.png)

Las imÃ¡genes de `data/binary_classifier/torax` se han procesado con el segmentador y guardado en `data/binary_classifier_torax_mask`

### Por quÃ© elegimos esta implementaciÃ³n?

La razÃ³n de por quÃ© elegimos [este repositorio](https://github.com/IlliaOvcharenko/lung-segmentation) es porque ya proveÃ­a los pesos del modelo entrenado en un dataset conocido. **Y mÃ¡s importante aÃºn posee:**
- El cÃ³digo de entrenamiento mediante el cual podemos verificar que ha sido entrenado correctamente (con splits de train, validaciÃ³n y test).
- Los splits (`splits.pk`) que nos permite replicar el entrenamiento realizado.

### Entrenando nuestro propio modelo

En el archivo `segmentation_train.py` se encuentra el entrenamiento de otro modelo UNet, cuya arquitectura hemos copiado de [Pytorch-UNet](https://github.com/milesial/Pytorch-UNet).

El loop de entrenamiento lo escribimos totalmente de cerp. Y para entrenar usamos un split de los datos con una mejor metodologÃ­a que la adoptada por el modelo usado en las secciones anteriores:
- Para el conjunto de desarrollo (train + validaciÃ³n): utilizamos *Shenzhen Dataset*
- Para el conjunto de test: utilizamos *Montgomery Dataset*

El objetivo con esta metodologÃ­a es simular que el dataset en el que se va a usar es distinto (posiblemente con distintos aparatos de imÃ¡gen) que el dataset de entrenamiento.

Los pesos del modelo se guardaron en `models/unet-enmed.pt`.

Las curvas costo y mÃ©tricas en validaciÃ³n y entrenamiento se grafican a continuaciÃ³n:

![Training graphs](./images/training.png)

En el split de test se han obtenido las siguientes mÃ©tricas: **Jaccard score - 0.7496, Dice score - 0.8401** . Se puede observar que con nuestrra metodologÃ­a los resultados son comparativamente peor. Se puede concluir que es importante usar mÃ¡s datos e incluir diferentes datasets.


#### Acotaciones y trabajo futuro

Algunas notas de pendientes y posibles mejores:
- Se ha utilizado un mini batch de tamaÃ±o 4. Esto es porque valores mayores no entraban en la memoria de la GPU usada (P5000). Se podrÃ­a simular mini-batches mÃ¡s grande utilizando `accumulation_steps` durante el entrenamiento.
- El tamaÃ±o del dataset de entrenamiento es pequeÃ±o ~530 imÃ¡genes (85% del Shenzhen Dataset). Se podrÃ­a aplicar data augmentation para enrobustecer el modelo. La modificaciÃ³n requiere ser cuidadoso de preservar la correspondencia de los pÃ­xeles entre inputs y mÃ¡scaras, pero esto lo maneja todo muy bien librerÃ­as como [albumentations](https://github.com/albumentations-team/albumentations).
- Data augmentation tambiÃ©n puede aplicarse en tiempo de inferencia (y luego hacer un merge los resultados). Esto requiere transformaciones inversibles, para lo cuÃ¡l se puede utilizar la librerÃ­a [ttach](https://github.com/qubvel/ttach)


# ApÃ©ndice I: Datasets

**Montgomery Dataset**  
- **Origen:** Montgomery County, Maryland, USA  
- **NÃºmero de imÃ¡genes:** ~138  

**Shenzhen Dataset**  
- **Origen:** Hospital NÂº3 de Shenzhen, China  
- **NÃºmero de imÃ¡genes:** ~662

Ambos datasets se encuentran en el siguiente [archivo](https://drive.google.com/file/d/1ffbbyoPf-I3Y0iGbBahXpWqYdGd7xxQQ/view). El directorio `images` contiene las radiografÃ­as y `masks` el source of truth de las mÃ¡scaras. Las mÃ¡scaras tienen el mismo nombre que su respectiva imÃ¡gen y se le ha adicionado el sufijo `_mask`. Los archivos del Shenzhen Dataset comienzan con `CHNCXR`.

```
ğŸ“ dataset/
â”œâ”€â”€ ğŸ“ images/
â”‚   â”œâ”€â”€ CHNCXR_0001_0.png  
â”‚   â”œâ”€â”€ CHNCXR_0002_0.png  
â”‚   â”œâ”€â”€ ...  (662 archivos)
â”‚   â”œâ”€â”€ MCUCXR_0001_0.png    
â”‚   â”œâ”€â”€ MCUCXR_0002_0.png    
â”‚   â””â”€â”€ ...  (138 archivos)
â””â”€â”€ ğŸ“ mask/
    â”œâ”€â”€ CHNCXR_0001_0_mask.png  
    â”œâ”€â”€ CHNCXR_0002_0_mask.png  
    â”œâ”€â”€ ...  (662 archivos)
    â”œâ”€â”€ MCUCXR_0001_0_mask.png  
    â”œâ”€â”€ MCUCXR_0002_0_mask.png  
    â””â”€â”€ ...  (138 archivos)
```

# ApÃ©ndice II: Referencias

Ronneberger, O., Fischer, P., & Brox, T. (2015). U-Net: Convolutional Networks for Biomedical Image Segmentation. *In Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI)* (pp. 234â€“241). Springer. https://doi.org/10.1007/978-3-319-24574-4_28
